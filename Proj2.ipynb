{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "#small_data = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/CS170_Small_Data__91.txt'\n",
    "small_text = \"/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/test/Sue/CS170_Small_Data__96.txt\"\n",
    "\n",
    "small_data_df = pd.read_csv(small_text,\n",
    "                            sep ='  ',\n",
    "                            engine = 'python',\n",
    "                            header = None)\n",
    "\n",
    "large_text = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/CS170_Large_Data__103.txt'\n",
    "\n",
    "\n",
    "large_data_df = pd.read_csv(large_text, \n",
    "                         sep='  ',\n",
    "                         engine = 'python',\n",
    "                         header=None)\n",
    "\n",
    "\n",
    "#small_arr = small_data\n",
    "small_data = small_data_df.to_numpy()\n",
    "\n",
    "large_data = large_data_df.to_numpy()\n",
    "\n",
    "#we take the dataframe, we are provided a set of features\n",
    "#we wish to add a feature\n",
    "#we do this by going through the data frame, add the feature_to_add to the current set\n",
    "#then we remove the features we don't want\n",
    "#def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "\n",
    "def stub(data_df,current_set,feature_to_add):\n",
    "    return np.random.rand()\n",
    "\n",
    "def dist(a,b):\n",
    "    diff = a[1:] - b[1:]\n",
    "    return(np.dot(diff,diff))\n",
    "\n",
    "#small_data_df = small_data_df.drop([2,4,5],axis=1)\n",
    "#def nn(data_df,current_set,feature_to_add): #this is correct\n",
    "def nn(data_df): #this is correct\n",
    "    \n",
    "    number_correctly_classified = 0\n",
    "    \n",
    "    for i in range(0,len(data_df)):\n",
    "        #object_to_classify = data_df.iloc[i]\n",
    "        object_to_classify = data_df[i,1:]\n",
    "        #label_object_to_classify = data_df.iloc[i][0]\n",
    "        label_object_to_classify = data_df[i,0]\n",
    "        \n",
    "        nearest_neighbor_distance = float('inf')\n",
    "        nearest_neighbor_location = float('inf')\n",
    "        \n",
    "        for k in range(0,len(data_df)):\n",
    "            if k!=i:            #object_to_classify,data_df.iloc[k]\n",
    "                #distance = dist(object_to_classify,data_df[k,1:])\n",
    "                distance = dist(data_df[i],data_df[k])\n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = k \n",
    "                    #data_df.iloc[nearest_neighbor_location][0]\n",
    "                    nearest_neighbor_label = data_df[nearest_neighbor_location,0]\n",
    "                    #print(nearest_neighbor_label)               \n",
    "        if label_object_to_classify == nearest_neighbor_label:\n",
    "            number_correctly_classified = number_correctly_classified +1 \n",
    "        \n",
    "    accuracy = number_correctly_classified / len(data_df)\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "#print(type(small_arr))\n",
    "\n",
    "\n",
    "def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "    current_set.append(feature_to_add)\n",
    "    \n",
    "    drops = []\n",
    "    x = 1\n",
    "    for x in range(1,data_df.shape[1]):\n",
    "        if x not in current_set:\n",
    "            drops.append(x)\n",
    "            \n",
    "        \n",
    "    #data_df.loc[:,drops] = 0\n",
    "    data_df[:,drops]=0\n",
    "\n",
    "    accuracy = nn(data_df)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "current_set = [1,3]\n",
    "feature_to_add = 6\n",
    "print(leave_one_out_cross_validation(small_data,current_set,feature_to_add))\n",
    "\n",
    "\n",
    "print(type(small_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the  1  level of the search tree\n",
      "[]\n",
      "Considering adding feature  1\n",
      "We have accuracies [0.874]\n",
      "[1]\n",
      "Considering adding feature  2\n",
      "We have accuracies [0.874, 0.874]\n",
      "[1, 2]\n",
      "Considering adding feature  3\n",
      "We have accuracies [0.874, 0.874, 0.874]\n",
      "[1, 2, 3]\n",
      "Considering adding feature  4\n",
      "We have accuracies [0.874, 0.874, 0.874, 0.874]\n",
      "[1, 2, 3, 4]\n",
      "Considering adding feature  5\n",
      "We have accuracies [0.874, 0.874, 0.874, 0.874, 0.874]\n",
      "[1, 2, 3, 4, 5]\n",
      "Considering adding feature  6\n",
      "We have accuracies [0.874, 0.874, 0.874, 0.874, 0.874, 0.874]\n",
      "On level  1  I added feature 1  to current set with accuracy 0.874\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "On the  2  level of the search tree\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "[1, 2, 3, 4, 5, 6, 1]\n",
      "On level  2  I added feature []  to current set with accuracy 0\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "On the  3  level of the search tree\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "[1, 2, 3, 4, 5, 6, 1, []]\n",
      "On level  3  I added feature []  to current set with accuracy 0\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "On the  4  level of the search tree\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], []]\n",
      "On level  4  I added feature []  to current set with accuracy 0\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "On the  5  level of the search tree\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], []]\n",
      "On level  5  I added feature []  to current set with accuracy 0\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "On the  6  level of the search tree\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], []]\n",
      "On level  6  I added feature []  to current set with accuracy 0\n",
      "[1, 2, 3, 4, 5, 6, 1, [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "def feature_search_demo(data):\n",
    "    current_set_of_features = []\n",
    "    acc_at_level=[]\n",
    "    for i in range(1,data.shape[1]):#level\n",
    "        print(\"On the \",i,\" level of the search tree\")\n",
    "        feature_to_add_at_this_level = []\n",
    "        best_so_far_acc = 0\n",
    "        for k in range(1,data.shape[1]):#features\n",
    "            print(current_set_of_features)\n",
    "            if k not in current_set_of_features:\n",
    "                print(\"Considering adding feature \",k)\n",
    "                \n",
    "                accuracy = leave_one_out_cross_validation(data,current_set_of_features,k)\n",
    "                acc_at_level.append(accuracy)\n",
    "                print(\"We have accuracies\",acc_at_level)\n",
    "                \n",
    "                if (accuracy > best_so_far_acc):\n",
    "                    best_so_far_acc = accuracy\n",
    "                    feature_to_add_at_this_level = k\n",
    "                    \n",
    "        current_set_of_features.append(feature_to_add_at_this_level)\n",
    "        print(\"On level \",i,\" I added feature\",feature_to_add_at_this_level,\" to current set with accuracy\",best_so_far_acc)\n",
    "        print(current_set_of_features)\n",
    "        \n",
    "feature_search_demo(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data_df):\n",
    "#def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "    number_correctly_classified = 0\n",
    "    \n",
    "    for i in range(1,len(data_df)):\n",
    "        object_to_classify = data_df.iloc[i]\n",
    "        label_object_to_classify = data_df.iloc[i][0]\n",
    "        \n",
    "        nearest_neighbor_distance = float('inf')\n",
    "        nearest_neighbor_location = float('inf')\n",
    "        \n",
    "        for k in range(1,len(data_df)):\n",
    "            if k!=i:\n",
    "                distance = math.sqrt(sum(object_to_classify - data_df.iloc[k])**2)\n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = k\n",
    "                    nearest_neighbor_label = data_df.iloc[nearest_neighbor_location][0]\n",
    "                #print(\"Ask if \", i, \" is neighest neighbor with\",k)\n",
    "        \n",
    "        #print(\"Looping over i, at the \",i,\"location\")\n",
    "        #print(\"The \",i,\"th object is in class\",label_object_to_classify)\n",
    "        if label_object_to_classify == nearest_neighbor_label:\n",
    "            number_correctly_classified +=1\n",
    "        #print(\"Object \",i, \" is class \", label_object_to_classify)\n",
    "        #print(\"It's nearest neighbor is \", nearest_neighbor_location, \" which is in class \", nearest_neighbor_label)\n",
    "    accuracy = number_correctly_classified / len(data_df)\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "        \n",
    "knn(small_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
