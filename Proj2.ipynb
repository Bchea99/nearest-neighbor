{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for k in current_set:\\n        if k not in current_set:\\n            #data_df[k].values[:] = 0 #set all column values not within current set to 0\\n            small_data_df = small_data_df.drop([k],axis=1)'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "#small_data = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/CS170_Small_Data__91.txt'\n",
    "small_data = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/test/Sue/CS170_Small_Data__96.txt'\n",
    "small_data_df = pd.read_csv(small_data,\n",
    "                            sep ='  ',\n",
    "                            engine = 'python',\n",
    "                            header = None)\n",
    "\n",
    "large_data = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/CS170_Large_Data__103.txt'\n",
    "large_data_df = pd.read_csv(large_data, \n",
    "                         sep='  ',\n",
    "                         engine = 'python',\n",
    "                         header=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#we take the dataframe, we are provided a set of features\n",
    "#we wish to add a feature\n",
    "#we do this by going through the data frame, add the feature_to_add to the current set\n",
    "#then we remove the features we don't want\n",
    "#def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "\n",
    "def stub(data_df,current_set,feature_to_add):\n",
    "    return np.random.rand()\n",
    "\n",
    "def dist(a,b):\n",
    "    diff = a[1:] - b[1:]\n",
    "    return(np.dot(diff,diff))\n",
    "\n",
    "#small_data_df = small_data_df.drop([2,4,5],axis=1)\n",
    "def nn(data_df,current_set,feature_to_add): #this is correct\n",
    "    current_set.append(feature_to_add)\n",
    "    \n",
    "    drops = []\n",
    "    x = 1\n",
    "    for x in data_df.iloc[:,1:]:\n",
    "        if x not in current_set:\n",
    "            drops.append(x)\n",
    "            \n",
    "        \n",
    "    data_df.loc[:,drops] = 0\n",
    "    number_correctly_classified = 0\n",
    "    \n",
    "    for i in range(0,len(data_df)):\n",
    "        object_to_classify = data_df.iloc[i]\n",
    "        #object_to_classify = data_df[i]\n",
    "        label_object_to_classify = data_df.iloc[i][0]\n",
    "        \n",
    "        \n",
    "        nearest_neighbor_distance = float('inf')\n",
    "        nearest_neighbor_location = float('inf')\n",
    "        \n",
    "        for k in range(0,len(data_df)):\n",
    "            if k!=i:\n",
    "                distance = dist(object_to_classify,data_df.iloc[k])\n",
    "\n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = k\n",
    "                    nearest_neighbor_label = data_df.iloc[nearest_neighbor_location][0]\n",
    "                                   \n",
    "        if label_object_to_classify == nearest_neighbor_label:\n",
    "            number_correctly_classified = number_correctly_classified +1 \n",
    "        \n",
    "    accuracy = number_correctly_classified / len(data_df)\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "'''   \n",
    "current_set = [1,2]\n",
    "feature_to_add = 3\n",
    "nn(small_data_df,current_set,feature_to_add)'''    \n",
    "\n",
    "def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "    current_set.append(feature_to_add)\n",
    "    not_in_set = []\n",
    "    for k in current_set:\n",
    "        if k not in current_set:\n",
    "            data_df.iloc[:,k] = 0 #set all column values not within current set to 0\n",
    "            #data_df = data_df.drop([k],axis=1)\n",
    "\n",
    "    accuracy = nn(data_df)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#current_set = [1,3,6]\n",
    "'''for k in current_set:\n",
    "        if k not in current_set:\n",
    "            #data_df[k].values[:] = 0 #set all column values not within current set to 0\n",
    "            small_data_df = small_data_df.drop([k],axis=1)'''\n",
    "    \n",
    "#small_data_df = small_data_df.drop([2,4,5],axis=1)\n",
    "#large_data_df = large_data_df.drop([])\n",
    "#small_data_df = \n",
    "#small_data_df.iloc[:,2] = 0\n",
    "#small_data_df.iloc[:,4] = 0\n",
    "#small_data_df.iloc[:,5] = 0\n",
    "#for col in small_data_df.columns\n",
    " \n",
    "#small_data_df.head()\n",
    "#knn(small_data_df)       \n",
    "#small_data_df.head()\n",
    "\n",
    "#nn(small_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the  1  level of the search tree\n",
      "Considering adding feature  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adding feature  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adding feature  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adding feature  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adding feature  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adding feature  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/_z0dpj9528j3trt78v6wyhc00000gn/T/ipykernel_55864/305185325.py:33: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  diff = a[1:] - b[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On level  1  I added feature 1  to current set with accuracy 0.874\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1]\n",
      "On the  2  level of the search tree\n",
      "On level  2  I added feature []  to current set with accuracy 0\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, [], [], [], [], [], []]\n",
      "On the  3  level of the search tree\n",
      "On level  3  I added feature []  to current set with accuracy 0\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "On the  4  level of the search tree\n",
      "On level  4  I added feature []  to current set with accuracy 0\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "On the  5  level of the search tree\n",
      "On level  5  I added feature []  to current set with accuracy 0\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "On the  6  level of the search tree\n",
      "On level  6  I added feature []  to current set with accuracy 0\n",
      "[1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "def feature_search_demo(data_df):\n",
    "    current_set_of_features = []\n",
    "    i = 1\n",
    "    #for i in range(len(small_data_df)-490):\n",
    "    for i in data_df.iloc[:,1:]:\n",
    "        print(\"On the \",i,\" level of the search tree\")\n",
    "        feature_to_add = []\n",
    "        best_so_far_acc = 0\n",
    "        #k = 1\n",
    "        for k in data_df.iloc[:,1:]:\n",
    "            if k not in current_set_of_features:\n",
    "                print(\"Considering adding feature \",k)\n",
    "                accuracy = nn(data_df,current_set_of_features,k)\n",
    "                #print(\"We have accuracy\",accuracy)\n",
    "                if (accuracy > best_so_far_acc):\n",
    "                    best_so_far_acc = accuracy\n",
    "                    feature_to_add = k\n",
    "            current_set_of_features.append(feature_to_add)\n",
    "        print(\"On level \",i,\" I added feature\",feature_to_add,\" to current set with accuracy\",best_so_far_acc)\n",
    "        print(current_set_of_features)\n",
    "        \n",
    "feature_search_demo(small_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [254], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[39m#print(accuracy)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[0;32m---> 31\u001b[0m knn(small_data_df)\n",
      "Cell \u001b[0;32mIn [254], line 14\u001b[0m, in \u001b[0;36mknn\u001b[0;34m(data_df)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(data_df)):\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m k\u001b[39m!=\u001b[39mi:\n\u001b[0;32m---> 14\u001b[0m         distance \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39msum\u001b[39m(object_to_classify \u001b[39m-\u001b[39;49m data_df\u001b[39m.\u001b[39;49miloc[k])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     15\u001b[0m         \u001b[39mif\u001b[39;00m distance \u001b[39m<\u001b[39m nearest_neighbor_distance:\n\u001b[1;32m     16\u001b[0m             nearest_neighbor_distance \u001b[39m=\u001b[39m distance\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/arraylike.py:110\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__sub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__sub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49msub)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[1;32m   6258\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[0;32m-> 6259\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/base.py:1327\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1327\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_result(result, name\u001b[39m=\u001b[39;49mres_name)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:3228\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   3224\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   3226\u001b[0m \u001b[39m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m \u001b[39m#  would set it back to self.name\u001b[39;00m\n\u001b[0;32m-> 3228\u001b[0m out\u001b[39m.\u001b[39;49mname \u001b[39m=\u001b[39m name\n\u001b[1;32m   3229\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:5915\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   5914\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 5915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   5916\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   5917\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:663\u001b[0m, in \u001b[0;36mSeries.name\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39m@name\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m    662\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m, value: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 663\u001b[0m     validate_all_hashable(value, error_name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    664\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_name\u001b[39m\u001b[39m\"\u001b[39m, value)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1744\u001b[0m, in \u001b[0;36mvalidate_all_hashable\u001b[0;34m(error_name, *args)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_all_hashable\u001b[39m(\u001b[39m*\u001b[39margs, error_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1726\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[39m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m    None\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1744\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(is_hashable(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args):\n\u001b[1;32m   1745\u001b[0m         \u001b[39mif\u001b[39;00m error_name:\n\u001b[1;32m   1746\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_name\u001b[39m}\u001b[39;00m\u001b[39m must be a hashable type\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def knn(data_df):\n",
    "#def leave_one_out_cross_validation(data_df,current_set,feature_to_add):\n",
    "    number_correctly_classified = 0\n",
    "    \n",
    "    for i in range(1,len(data_df)):\n",
    "        object_to_classify = data_df.iloc[i]\n",
    "        label_object_to_classify = data_df.iloc[i][0]\n",
    "        \n",
    "        nearest_neighbor_distance = float('inf')\n",
    "        nearest_neighbor_location = float('inf')\n",
    "        \n",
    "        for k in range(1,len(data_df)):\n",
    "            if k!=i:\n",
    "                distance = math.sqrt(sum(object_to_classify - data_df.iloc[k])**2)\n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = k\n",
    "                    nearest_neighbor_label = data_df.iloc[nearest_neighbor_location][0]\n",
    "                #print(\"Ask if \", i, \" is neighest neighbor with\",k)\n",
    "        \n",
    "        #print(\"Looping over i, at the \",i,\"location\")\n",
    "        #print(\"The \",i,\"th object is in class\",label_object_to_classify)\n",
    "        if label_object_to_classify == nearest_neighbor_label:\n",
    "            number_correctly_classified +=1\n",
    "        #print(\"Object \",i, \" is class \", label_object_to_classify)\n",
    "        #print(\"It's nearest neighbor is \", nearest_neighbor_location, \" which is in class \", nearest_neighbor_label)\n",
    "    accuracy = number_correctly_classified / len(data_df)\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "        \n",
    "knn(small_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
