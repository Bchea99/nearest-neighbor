{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncurrent_set = [1]\\nfeature_to_add = 2\\n\\nprint(leave_one_out_cross_validation(small_data,current_set,feature_to_add))\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "import math\n",
    "import random\n",
    "\n",
    "#small_data = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/CS170_Small_Data__91.txt'\n",
    "small_text = \"/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/test/Sue/CS170_Small_Data__96.txt\"\n",
    "\n",
    "small_data_df = pd.read_csv(small_text,\n",
    "                            sep ='  ',\n",
    "                            engine = 'python',\n",
    "                            header = None)\n",
    "\n",
    "large_text = '/Users/brandonchea/Desktop/Fall_2022/CS170/Project2/Datasets/test/Sue/CS170_Large_Data__21.txt'\n",
    "\n",
    "\n",
    "large_data_df = pd.read_csv(large_text, \n",
    "                         sep='  ',\n",
    "                         engine = 'python',\n",
    "                         header=None)\n",
    "\n",
    "\n",
    "#small_arr = small_data\n",
    "small_data = small_data_df.to_numpy()\n",
    "\n",
    "large_data = large_data_df.to_numpy()\n",
    "\n",
    "\n",
    "def stub(data_df,current_set,feature_to_add):\n",
    "    random.seed(feature_to_add)\n",
    "    return random.random()\n",
    "\n",
    "def dist(a,b):\n",
    "    diff = a[1:] - b[1:]\n",
    "    return(np.dot(diff,diff))\n",
    "\n",
    "\n",
    "def nn(data_df): #this is correct\n",
    "    \n",
    "    number_correctly_classified = 0\n",
    "    \n",
    "    for i in range(0,len(data_df)):\n",
    "        #object_to_classify = data_df.iloc[i]\n",
    "        object_to_classify = data_df[i,1:]\n",
    "        #label_object_to_classify = data_df.iloc[i][0]\n",
    "        label_object_to_classify = data_df[i,0]\n",
    "        \n",
    "        nearest_neighbor_distance = float('inf')\n",
    "        nearest_neighbor_location = float('inf')\n",
    "        \n",
    "        for k in range(0,len(data_df)):\n",
    "            if k!=i:            #object_to_classify,data_df.iloc[k]\n",
    "                #distance = dist(object_to_classify,data_df[k,1:])\n",
    "                distance = dist(data_df[i],data_df[k])\n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = k \n",
    "                    #data_df.iloc[nearest_neighbor_location][0]\n",
    "                    nearest_neighbor_label = data_df[nearest_neighbor_location,0]\n",
    "                    #print(nearest_neighbor_label)               \n",
    "        if label_object_to_classify == nearest_neighbor_label:\n",
    "            number_correctly_classified = number_correctly_classified +1 \n",
    "        \n",
    "    accuracy = number_correctly_classified / len(data_df)\n",
    "    #print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def leave_one_out_cross_validation_forward(data_df,current_set,feature_to_add):\n",
    "    new_current = current_set[:]\n",
    "    new_current.append(feature_to_add)\n",
    "    \n",
    "    drops = []\n",
    "    x = 1\n",
    "    for x in range(1,data_df.shape[1]): #iterate through the columns\n",
    "        if x not in new_current: #drop that column if it is not inside of the current set\n",
    "            drops.append(x)\n",
    "            \n",
    "        \n",
    "    #data_df.loc[:,drops] = 0\n",
    "    new_data_df = data_df.copy()\n",
    "    new_data_df[:,drops]=0 #\n",
    "\n",
    "    accuracy = nn(new_data_df)\n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "current_set = [1]\n",
    "feature_to_add = 2\n",
    "\n",
    "print(leave_one_out_cross_validation(small_data,current_set,feature_to_add))\n",
    "'''\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(data):\n",
    "    current_set_of_features = [] #these are the list with the best accuracies at each level\n",
    "    best_accuracies=[]\n",
    "    #relevant_feature_tuples = []\n",
    "    for i in range(1,data.shape[1]):#level\n",
    "        \n",
    "        #print(\"On the \",i,\" level of the search tree\")\n",
    "        \n",
    "        feature_to_add_at_this_level = []\n",
    "        best_so_far_acc = 0\n",
    "        \n",
    "        for k in range(1,data.shape[1]):#features\n",
    "            if k not in current_set_of_features:\n",
    "                #print(\"Considering adding feature \",k)\n",
    "                 \n",
    "                accuracy = leave_one_out_cross_validation_forward(data,current_set_of_features,k)\n",
    "                print(\"Feature(s) {\",*current_set_of_features,k,\"} accuracy is \",accuracy)\n",
    "                if (accuracy > best_so_far_acc):\n",
    "                    best_so_far_acc = accuracy\n",
    "                    feature_to_add_at_this_level = k\n",
    "        best_accuracies.append(best_so_far_acc)                     \n",
    "        current_set_of_features.append(feature_to_add_at_this_level)\n",
    "        #relevant_feature_tuples.append(current_set_of_features)\n",
    "        print(\"On level \",i,\" I added feature\",feature_to_add_at_this_level,\" to current set with accuracy\",best_so_far_acc)\n",
    "    print(\"These are our features\",current_set_of_features)\n",
    "    print(\"These are the accuracies\",best_accuracies)\n",
    "    #print(\"These are relevant feature combinations\",relevant_feature_tuples)\n",
    "        \n",
    "forward_feature_selection(small_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyArray(data):\n",
    "    current = []\n",
    "    for i in range(1,data.shape[1]):\n",
    "        current.append(i)\n",
    "    return current\n",
    "\n",
    "#current = []\n",
    "current = copyArray(large_data)\n",
    "print(*current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_cross_validation_elimination(data_df,current_set,feature_to_remove):\n",
    "    new_current = current_set[:]\n",
    "    new_current.remove(feature_to_remove)\n",
    "    \n",
    "    drops = []\n",
    "    x = 1\n",
    "    for x in range(1,data_df.shape[1]): #iterate through the columns\n",
    "        if x not in new_current: #drop that column if it is not inside of the current set\n",
    "            drops.append(x)\n",
    "            \n",
    "        \n",
    "    #data_df.loc[:,drops] = 0\n",
    "    new_data_df = data_df.copy()\n",
    "    new_data_df[:,drops]=0 #\n",
    "\n",
    "    accuracy = nn(new_data_df)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination_feature_selection(data):\n",
    "    current_set_of_features = copyArray(data)\n",
    "    best_accuracies=[]\n",
    "    #relevant_feature_tuples = []\n",
    "    for i in range(1,data.shape[1]):#level\n",
    "        \n",
    "        print(\"On level \",i,\" of the search tree\")\n",
    "        \n",
    "        feature_to_add_at_this_level = []\n",
    "        best_so_far_acc = 0\n",
    "        \n",
    "        for k in range(1,data.shape[1]):#features\n",
    "            if k in current_set_of_features:\n",
    "                #print(\"Considering adding feature \",k)\n",
    "                 \n",
    "                accuracy = leave_one_out_cross_validation_elimination(data,current_set_of_features,k)\n",
    "                print(\"Feature(s) {\",*current_set_of_features,\"} with removal of\",k,\" Has accuracy:\",accuracy)\n",
    "                if (accuracy > best_so_far_acc):\n",
    "                    best_so_far_acc = accuracy\n",
    "                    feature_to_add_at_this_level = k\n",
    "        best_accuracies.append(best_so_far_acc)                     \n",
    "        current_set_of_features.remove(feature_to_add_at_this_level)\n",
    "        #relevant_feature_tuples.append(current_set_of_features)\n",
    "        print(\"On level \",i,\" I removed feature\",feature_to_add_at_this_level,\" from the current set with accuracy\",best_so_far_acc)\n",
    "    print(\"These are our features\",current_set_of_features)\n",
    "    print(\"These are the accuracies\",best_accuracies)\n",
    "\n",
    "backward_elimination_feature_selection(small_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
